method: checkboard

# WandB log
project: gmflow_project

# Model structure definition
model:
  type: GMFlow
  denoising:
    type: GMFlowMLP2DDenoiser
    num_gaussians: 64
  flow_loss:
    type: GMFlowNLLLoss
    log_cfgs:
      type: quartile
      prefix_name: loss_trans
      total_timesteps: 1000
    data_info:
      pred_means: means
      target: x_t_low
      pred_logstds: logstds
      pred_logweights: logweights
  test_cfg:
    output_mode: sample
    sampler: GMFlowSDE
    num_timesteps: 8
    order: 2
  denoising_mean_mode: U
  timestep_sampler:
    type: continuous
    shift: 1.0
    logit_normal_enable: False
    num_timesteps: 1000
  diffusion_use_ema: True

  noise_sampler:
    type: "gaussian"

# Training related parameters
train:
  batch_size: 8
  epochs: 1000
  lr: 0.0001
  weight_decay: 0.0
  optimizer: adam
  scheduler: cosine             # Optional: constant, step, cosine
  accumulation_steps: 2
  clip_grad: 1.0
  warmup_steps: 500
  eval_interval: 5
  output_dir: outputs/toymodel_exp
  save_checkpoint: false
  save_interval: 50
  
test:
  n_samples: 10000
  out_path: outputs/toymodel_exp/test_samples.png

# Data configuration
data:
  train:
    type: CheckerboardData
    n_rc: 4
    n_samples: 1e6
    thickness: 1.0
    scale: 1.0
    shift: [0.0, 0.0]
    rotation: 0.0
  train_dataloader:
    num_workers: 4
    batch_size: 32

# Mixed precision control
fp16: true

# Optional flags
debug: true
